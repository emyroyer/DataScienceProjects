{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 22:01:29) [MSC v.1900 64 bit (AMD64)]\n",
      "numpy: 1.17.0\n",
      "matplotlib: 3.1.1\n",
      "pandas: 0.25.0\n",
      "sklearn: 0.22.2.post1\n",
      "seaborn: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib: {}'.format(mpl.__version__))\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "print('seaborn: {}'.format(sns.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "path = r'C:\\Users\\emyro\\Downloads\\titanic\\train.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Explore the first ten rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count up all the missing values for each feature in the data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex        Age  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.000000   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
       "2                             Heikkinen, Miss. Laina  female  26.000000   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.000000   \n",
       "4                           Allen, Mr. William Henry    male  35.000000   \n",
       "5                                   Moran, Mr. James    male  29.699118   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.000000   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.000000   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.000000   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.000000   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  \n",
       "5      0      0            330877   8.4583   NaN        Q  \n",
       "6      0      0             17463  51.8625   E46        S  \n",
       "7      3      1            349909  21.0750   NaN        S  \n",
       "8      0      2            347742  11.1333   NaN        S  \n",
       "9      1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace age with a value that would sway the data one way or the other\n",
    "# since age does not mean anything in itself, replace missing values by the average age\n",
    "data['Age'].fillna(data['Age'].mean(), inplace = True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine SibSp & Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, col in enumerate(['SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=data, kind='point', aspect=2, ) # do a category plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age            Ticket     Fare Cabin Embarked  Family_cnt  \n",
       "0    male  22.0         A/5 21171   7.2500   NaN        S           1  \n",
       "1  female  38.0          PC 17599  71.2833   C85        C           1  \n",
       "2  female  26.0  STON/O2. 3101282   7.9250   NaN        S           0  \n",
       "3  female  35.0            113803  53.1000  C123        S           1  \n",
       "4    male  35.0            373450   8.0500   NaN        S           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SibSp and Parch follow the same trend and are reletd so let's combine them\n",
    "data['Family_cnt'] = data['SibSp'] + data['Parch']\n",
    "\n",
    "# drop unecessary varaibles\n",
    "# drop passenger Id feature as well\n",
    "data.drop(['PassengerId', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
    "# inplace = True laters the data in place, without creating new data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean categorical varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        0\n",
       "Pclass          0\n",
       "Name            0\n",
       "Sex             0\n",
       "Age             0\n",
       "Ticket          0\n",
       "Fare            0\n",
       "Cabin         687\n",
       "Embarked        2\n",
       "Family_cnt      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "False    0.666667\n",
       "True     0.299854\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an indicator for cabin\n",
    "# it will create two data frame: one where cabin is missing and one where it is not\n",
    "data.groupby(data['Cabin'].isnull())['Survived'].mean()\n",
    "# the survival rate is drastically lower when cabin is missing\n",
    "# true is when cabin is missing and survival rate is 29%\n",
    "# so people who did not have cabin were less likely to survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age            Ticket     Fare Cabin Embarked  Family_cnt  \\\n",
       "0    male  22.0         A/5 21171   7.2500   NaN        S           1   \n",
       "1  female  38.0          PC 17599  71.2833   C85        C           1   \n",
       "2  female  26.0  STON/O2. 3101282   7.9250   NaN        S           0   \n",
       "3  female  35.0            113803  53.1000  C123        S           1   \n",
       "4    male  35.0            373450   8.0500   NaN        S           0   \n",
       "\n",
       "   Cabin_ind  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the missing value by the fact the poeple did not have a cabin\n",
    "data['Cabin_ind']=np.where(data['Cabin'].isnull(), 0, 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age            Ticket     Fare Cabin Embarked  Family_cnt  Cabin_ind  \n",
       "0  22.0         A/5 21171   7.2500   NaN        S           1          0  \n",
       "1  38.0          PC 17599  71.2833   C85        C           1          1  \n",
       "2  26.0  STON/O2. 3101282   7.9250   NaN        S           0          0  \n",
       "3  35.0            113803  53.1000  C123        S           1          1  \n",
       "4  35.0            373450   8.0500   NaN        S           0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the male vs female by numeric values\n",
    "gender_num = {'male':0, 'female':1}\n",
    "data['Sex'] = data['Sex'].map(gender_num)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Family_cnt  Cabin_ind\n",
       "0         0       3    0  22.0   7.2500           1          0\n",
       "1         1       1    1  38.0  71.2833           1          1\n",
       "2         1       3    1  26.0   7.9250           0          0\n",
       "3         1       1    1  35.0  53.1000           1          1\n",
       "4         0       3    0  35.0   8.0500           0          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary variables\n",
    "data.drop(['Cabin', 'Embarked', 'Name', 'Ticket'], axis =1, inplace=True)\n",
    "# Why to drop Embarked?\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the cleaned data\n",
    "#data.to_csv('titanic_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.drop('Survived', axis=1)\n",
    "labels = data['Survived']\n",
    "\n",
    "# test_train split can only slipt the data in two so we need to do it in 3 passes to get a avlidation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out all data\n",
    "#X_train.to_csv('train_feature.csv', index=False)\n",
    "#X_val.to_csv('val_feature.csv', index=False)\n",
    "#X_test.to_csv('test_feature.csv', index=False)\n",
    "\n",
    "#y_train.to_csv('train_label.csv', index=False)\n",
    "#y_val.to_csv('val_label.csv', index=False)\n",
    "#y_test.to_csv('test_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression is a statistical process for estiating the relationship among variables, \n",
    "# often to make a prediction about some outcome\n",
    "\n",
    "# Logistic Regression is a form of regression where the target variable is binary (0 or 1, or True or False for example)\n",
    "# this is different than linear regression\n",
    "\n",
    "# Linear Regression  : y = mx + b\n",
    "# Logistic Regression: y = 1 / (1 + exp(-(mx+b))) \n",
    "\n",
    "# When to use it? General guideline\n",
    "# For binary target variable\n",
    "# use if Transparency is important or interested in significance of predictors\n",
    "# use with fairly well-behaved data\n",
    "# need a quick initial benchmark model with fairly well-behaved data - quick to train\n",
    "\n",
    "# When NOT to use it?\n",
    "# for continuous target variable \n",
    "# Not for massive amount of data (rows or columns; fat vs skinny data)\n",
    "# Not for unwieldly data with lots of outliners, misisng values, skwed features or complexe relationships\n",
    "# if performance is the only thing that matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#To print all the hyperparameter that we can tune:\n",
    "LogisticRegression()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_predict_proba_lr',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'sparsify']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's focus on the C parameter, which has a default value of 1.0\n",
    "# See attribute and methods contained within that object\n",
    "dir(LogisticRegression)\n",
    "# see .fit and .predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The C hyperparameter is a regularization parameter in logistic regression that controls how closely the model fits to the training data\n",
    "# Regularization is a technique used to reduce overfitting by discouraging overly complex models in some way\n",
    "\n",
    "# C = 1 / lambda, lambda is actually the regularization parameter\n",
    "# when lambda tends toward zero, C tends toward infinity\n",
    "# Thus lambda = 0 means low regularization, high complexity and more likely to overfit!\n",
    "\n",
    "# when lambda tends toward infinity, C tends towar zero\n",
    "# this means high regularization, low complexity and more likely to underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross-validation is to robustely train and test a model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings # for future versions of sklearn\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# C = 1 / lambda\n",
    "\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "    \n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std*2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 1}\n",
      "\n",
      "0.67 (+/-0.077) for {'C': 0.001}\n",
      "0.708 (+/-0.098) for {'C': 0.01}\n",
      "0.777 (+/-0.134) for {'C': 0.1}\n",
      "0.8 (+/-0.118) for {'C': 1}\n",
      "0.794 (+/-0.116) for {'C': 10}\n",
      "0.794 (+/-0.116) for {'C': 100}\n",
      "0.794 (+/-0.116) for {'C': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(lr, parameters, cv=5) # 5 for five folds\n",
    "cv.fit(X_train,y_train.values.ravel()) # fit on 4 of them and evaluate on the 4th\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the best fit model\n",
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_model.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "import joblib\n",
    "joblib.dump(cv.best_estimator_, 'LR_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A support Vector Machine (SVM) is a classifier that finds an optimal hyperplane that\n",
    "# maximizes the margin between two classes\n",
    "# Support vector is a perpendicular line between best fit line and the data points. \n",
    "# You want to maximize the length of those support vectors\n",
    "# Hyperplane is like a line but for 3D and more\n",
    "\n",
    "# So far, we require the data to be linearly separable, but for higher dimensions:\n",
    "# the kernel trick (or kernel method) transforms data that is not linearly separable \n",
    "# in n-dimensional space to a higher dimension where it is linearly separable.\n",
    "\n",
    "\n",
    "# When to use SVM?\n",
    "# for classification problem, not regression\n",
    "# For Binary target variable\n",
    "# when the feature-to-row ratio is very high: lots of features and few rows\n",
    "# for very complex relationship\n",
    "# when there is lots of outliners\n",
    "\n",
    "# When NOT to use it?\n",
    "# when feature-to-row ratio is low: few features and lots of rows\n",
    "# when transparency is important or interested in significance of predictors\n",
    "# when you are looking for a quick benchmark model. It takes time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC #support vector classifier\n",
    "\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_proba',\n",
       " '_compute_kernel',\n",
       " '_decision_function',\n",
       " '_dense_decision_function',\n",
       " '_dense_fit',\n",
       " '_dense_predict',\n",
       " '_dense_predict_proba',\n",
       " '_estimator_type',\n",
       " '_get_coef',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_impl',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_predict_log_proba',\n",
       " '_predict_proba',\n",
       " '_sparse_decision_function',\n",
       " '_sparse_fit',\n",
       " '_sparse_kernels',\n",
       " '_sparse_predict',\n",
       " '_sparse_predict_proba',\n",
       " '_validate_for_predict',\n",
       " '_validate_targets',\n",
       " '_warn_from_fit_status',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'n_support_',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# focus on the C hyperparameter and the kernel hyperparameter\n",
    "dir(SVC) # for a look at all the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.796 (+/-0.115) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.654 (+/-0.06) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.115) for {'C': 1, 'kernel': 'linear'}\n",
      "0.661 (+/-0.048) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.115) for {'C': 10, 'kernel': 'linear'}\n",
      "0.684 (+/-0.07) for {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "# The C hyperparameter is a penalty term that determines how closely the model fits to the training set\n",
    "# This is aregularization parameter\n",
    "# A high value of C means low regularization (large penalty) and small margins\n",
    "# A low value of C means small penalty for misclassification in training and large margins\n",
    "\n",
    "# the kernel trick!\n",
    "\n",
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(svc, parameters, cv=5) # 5 for five folds cross-validation\n",
    "cv.fit(X_train,y_train.values.ravel()) # fit on 4 of them and evaluate on the 5th\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_model.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(cv.best_estimator_, 'SVM_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-layer perceptron is a classic feed-forward artificial neural network,\n",
    "# the core component of deep learning.\n",
    "\n",
    "# A multi-layer perceptron is a connected series of nodes (in the form of a directed acylic\n",
    "# graph), where each node represents a function or a model.\n",
    "\n",
    "# When to use it?\n",
    "# for a categorical or continuous target variable\n",
    "# for very complex relationships or performance is the only thing that matters\n",
    "# when control over the training process is very important - lots of hyperparameters to control\n",
    "\n",
    "# When NOT to use it?\n",
    "# when need to do image recognition, time series, etc...\n",
    "# if care about trasparency and is interested in significance of predictors. multi-layer predictors model are like black-boxes\n",
    "# when need a quick benchmark model - lots of parameters to tweak\n",
    "# when you have limited data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to consider\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "print(MLPRegressor())\n",
    "print(MLPClassifier()) # same as for regressor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: The activation 'tanH' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "\n",
      "0.697 (+/-0.138) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.716 (+/-0.153) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.73 (+/-0.123) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.792 (+/-0.121) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.796 (+/-0.1) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.783 (+/-0.126) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.79 (+/-0.137) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.789 (+/-0.129) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.789 (+/-0.126) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "nan (+/-nan) for {'activation': 'tanH', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.699 (+/-0.11) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.697 (+/-0.081) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.704 (+/-0.092) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.744 (+/-0.116) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.762 (+/-0.103) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.766 (+/-0.1) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.796 (+/-0.082) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.775 (+/-0.149) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.794 (+/-0.104) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emyro\\.conda\\envs\\ScientificPython\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# activation\n",
    "# the activation function hyperparameter dictates the type of nonlinearity \n",
    "# that is introduced to the model (Sigmoid = logistic curve, TanH = hyperbolic tangent curve,\n",
    "# ReLU = rectified linear unit, etc...)\n",
    "\n",
    "# hidden_layer_sizes\n",
    "# Hidden_layer_sizes hyperparameter determines how many hidden layers there will be\n",
    "# and how many nodes in each layer\n",
    "# overfitting if too many nodes\n",
    "\n",
    "# Learning rate\n",
    "# The learning rate hyperparameter facilitates both how quickly and whether or not\n",
    "# the algorithm will find the optimal solution\n",
    "\n",
    "mlpC = MLPClassifier()\n",
    "parameters = {\n",
    "    'activation': ['relu', 'tanH', 'logistic'],\n",
    "    'hidden_layer_sizes': [(10,),(50,),(100,)], # first number is number of node; leaving second numer blank implies that hidden layers = 1\n",
    "    'learning_rate': ['constant','invscaling','adaptive']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(mlpC, parameters, cv=5) # 5 for five folds cross-validation\n",
    "cv.fit(X_train,y_train.values.ravel()) # fit on 4 of them and evaluate on the 5th\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLPClassifier_model.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(cv.best_estimator_, 'MLPClassifier_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random forest merges a collection of independent decision tress to get a more\n",
    "# accurate and stable prediction.\n",
    "# Ensemble methods combine several machine learning models in order to decrease\n",
    "# both bias and variance.\n",
    "\n",
    "# When to use it?\n",
    "# for categorical and continuous target variable\n",
    "# if interested in significance of predictors\n",
    "# if need a quick benchmark model - quick to run\n",
    "# If you have messy data, such as missing values, outliers\n",
    "\n",
    "# When NOT to use it?\n",
    "# if you are solving very complex, novel problem\n",
    "# if transparency is important\n",
    "# If prediction time is important\n",
    "# does not always give the best performance, but good swiss army knife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "BEST PARAMS: {'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "0.749 (+/-0.114) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.796 (+/-0.117) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.8 (+/-0.104) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.8 (+/-0.106) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.826 (+/-0.097) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.822 (+/-0.113) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.792 (+/-0.096) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.82 (+/-0.07) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.82 (+/-0.059) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.824 (+/-0.062) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.815 (+/-0.036) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.809 (+/-0.032) for {'max_depth': 16, 'n_estimators': 250}\n",
      "0.796 (+/-0.025) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.809 (+/-0.038) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.811 (+/-0.036) for {'max_depth': 32, 'n_estimators': 250}\n",
      "0.788 (+/-0.065) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.813 (+/-0.059) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.813 (+/-0.033) for {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "print(RandomForestClassifier())\n",
    "print(RandomForestRegressor())\n",
    "\n",
    "#Hyperparamters to consider\n",
    "#n_estimators\n",
    "# The n_estimators hyperparameter controls how many individual decision trees will be built.\n",
    "\n",
    "#max_depth\n",
    "# The max-depth hyperparameter controls how deep each individual decision tree can go.\n",
    "\n",
    "rfC = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None] # None let the tree goes deep as it can\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rfC, parameters, cv=5) # 5 for five folds cross-validation\n",
    "cv.fit(X_train,y_train.values.ravel()) # fit on 4 of them and evaluate on the 5th\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RFClassifier_model.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(cv.best_estimator_, 'RFClassifier_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting is an ensemble method that aggregates a number of waek models to create\n",
    "# one strong model\n",
    "# A weak model is one that is only slightly better than random guessing.\n",
    "# A strong model is one that is strongly correlated with the true classification.\n",
    "# Boosting effectively learns from its mistakes with each iteration.\n",
    "# Trainging process is not independent like it is in random forest\n",
    "# This is one of the most used algorithm and one of the most flexible!\n",
    "\n",
    "# We will try gradient boosted try, a specific variant of boosting\n",
    "\n",
    "# When to use boosting?\n",
    "# for classification and regression, so for categorical and continuous target variable\n",
    "# useful on nearly any type of problem\n",
    "# if interested in significance of predictors\n",
    "# if prediction time is important - it is fast at prediction time\n",
    "\n",
    "# When NOT to use boosting?\n",
    "# when transparency is important because individual trees are so many that it is complicated to understand all of them\n",
    "# if training time is imprtant or computer power is limited - it is slow to train\n",
    "# if data is really noisy - it has a tendency to overfit or fit the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "BEST PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.811 (+/-0.117) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.811 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.83 (+/-0.074) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.841 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.822 (+/-0.052) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.82 (+/-0.037) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.822 (+/-0.037) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.817 (+/-0.05) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.82 (+/-0.036) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.805 (+/-0.028) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.803 (+/-0.059) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.8 (+/-0.042) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.79 (+/-0.046) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.815 (+/-0.119) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.818 (+/-0.111) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.828 (+/-0.092) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.813 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.839 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.826 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.809 (+/-0.04) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.817 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.822 (+/-0.031) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.805 (+/-0.029) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.798 (+/-0.039) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.818 (+/-0.053) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.798 (+/-0.014) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.79 (+/-0.042) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.803 (+/-0.021) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.8 (+/-0.042) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.794 (+/-0.032) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.79 (+/-0.031) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.785 (+/-0.04) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.818 (+/-0.099) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.832 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.826 (+/-0.077) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.822 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.82 (+/-0.061) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.794 (+/-0.036) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.79 (+/-0.036) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.787 (+/-0.039) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.79 (+/-0.025) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.8 (+/-0.04) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.796 (+/-0.034) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.796 (+/-0.038) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.79 (+/-0.053) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.788 (+/-0.045) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.811 (+/-0.045) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.798 (+/-0.031) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.79 (+/-0.038) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.788 (+/-0.059) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.796 (+/-0.049) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.805 (+/-0.049) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.443 (+/-0.253) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.438 (+/-0.304) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.445 (+/-0.314) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.443 (+/-0.311) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.611 (+/-0.173) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.61 (+/-0.204) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.586 (+/-0.189) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.586 (+/-0.18) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.706 (+/-0.144) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.702 (+/-0.129) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.699 (+/-0.122) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.71 (+/-0.134) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.35 (+/-0.184) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.352 (+/-0.184) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.35 (+/-0.196) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.35 (+/-0.186) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.541 (+/-0.156) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.573 (+/-0.093) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.601 (+/-0.099) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.584 (+/-0.127) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.654 (+/-0.045) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.67 (+/-0.096) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.669 (+/-0.059) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.669 (+/-0.073) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "print(GradientBoostingClassifier())\n",
    "print(GradientBoostingRegressor())\n",
    "\n",
    "#Hyperparamters to consider\n",
    "#n_estimators\n",
    "# The n_estimators hyperparameter controls how many individual decision trees will be built.\n",
    "# need to train more shallow trees than in random forest\n",
    "\n",
    "#max_depth\n",
    "# The max-depth hyperparameter controls how deep each individual decision tree can go.\n",
    "# The trees must be shallower than for random forest\n",
    "\n",
    "#learning_rate\n",
    "# seen in perceptron. In Gradient Boosting, it controls the actual value of learning rate \n",
    "# and stays constant across the optimization process\n",
    "\n",
    "gbC = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gbC, parameters, cv=5) # 5 for five folds cross-validation\n",
    "cv.fit(X_train,y_train.values.ravel()) # fit on 4 of them and evaluate on the 5th\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBClassifier_model.pkl']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write out pickled model\n",
    "joblib.dump(cv.best_estimator_, 'GBClassifier_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which algorithm generates the best model for this given problem?\n",
    "\n",
    "# Latency\n",
    "# How long will it take to train?\n",
    "# How long will it take to predict?\n",
    "\n",
    "# Accuracy\n",
    "# How do they handle data of different size, such as short and fat, long and skinny?\n",
    "# How will they handle the complexity of feature relationships?\n",
    "# How will they handle messy data?\n",
    "\n",
    "# usually start with 6 or 7 models and narrow it down to 3 or 4, etc...\n",
    "\n",
    "#Summary table\n",
    "\n",
    "#          Problem type  Train speed   Predict speed    Interpretability   performance  performance with limited data\n",
    "\n",
    "#logistic  Classification  fast           fast             medium           lower     higher\n",
    "#regression\n",
    "\n",
    "#Support   \n",
    "#vector   Classification   slowest       moderate          low              medium    higher\n",
    "#machine\n",
    "\n",
    "#multilayer    Both        slow          moderate          low              high      lower\n",
    "#perception\n",
    "\n",
    "#random        Both        moderate     moderate           low               medium   lower\n",
    "#forest\n",
    "\n",
    "#boosted       Both        slow          fast               low             high      lower\n",
    "#trees     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from time import time\n",
    "\n",
    "models = {}\n",
    "\n",
    "for mdl in ['LR','SVM','MLPClassifier','RFClassifier','GBClassifier']:\n",
    "    models[mdl] = joblib.load('{}_model.pkl'.format(mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'SVM': SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'MLPClassifier': MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "               beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "               power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "               warm_start=False),\n",
       " 'RFClassifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=4, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'GBClassifier': GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "\n",
    "# accuracy = #predicted correctly / total # of examples\n",
    "\n",
    "# precision = #predicted as surviving that actually survived / total # of examples\n",
    "\n",
    "# recall = #predicted as surviving that actually survived / total # that actually survived\n",
    "\n",
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                  accuracy,\n",
    "                                                                                  precision,\n",
    "                                                                                  recall,\n",
    "                                                                                  round((end-start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- Accuracy: 0.775 / Precision: 0.712 / Recall: 0.646 / Latency: 0ms\n",
      "SVM -- Accuracy: 0.747 / Precision: 0.672 / Recall: 0.6 / Latency: 0ms\n",
      "MLPClassifier -- Accuracy: 0.781 / Precision: 0.724 / Recall: 0.646 / Latency: 0ms\n",
      "RFClassifier -- Accuracy: 0.803 / Precision: 0.788 / Recall: 0.631 / Latency: 0ms\n",
      "GBClassifier -- Accuracy: 0.815 / Precision: 0.808 / Recall: 0.646 / Latency: 0ms\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting -- Accuracy: 0.816 / Precision: 0.852 / Recall: 0.684 / Latency: 0ms\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test set\n",
    "evaluate_model('Gradient Boosting', models['GBClassifier'], X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ScientificPython] *",
   "language": "python",
   "name": "conda-env-.conda-ScientificPython-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
